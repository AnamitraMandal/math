[/
  Copyright 2018 Nick Thompson

  Distributed under the Boost Software License, Version 1.0.
  (See accompanying file LICENSE_1_0.txt or copy at
  http://www.boost.org/LICENSE_1_0.txt).
]

[section:signal_statistics Signal Statistics]

[heading Synopsis]

``
#include <boost/math/tools/signal_statistics.hpp>

namespace boost{ namespace math{ namespace tools {

    template<class Container>
    auto absolute_median(Container & c);

    template<class ForwardIterator>
    auto absolute_median(ForwardIterator first, ForwardIterator last);

    template<class Container>
    auto absolute_gini_coefficient(Container & c);

    template<class ForwardIterator>
    auto absolute_gini_coefficient(ForwardIterator first, ForwardIterator last);

    template<class Container>
    auto hoyer_sparsity(Container const & c);

    template<class ForwardIterator>
    auto hoyer_sparsity(ForwardIterator first, ForwardIterator last);

    template<class Container>
    auto shannon_entropy(Container const & c);

    template<class ForwardIterator>
    auto shannon_entropy(ForwardIterator first, ForwardIterator last);

    template<class Container>
    auto shannon_cost(Container const & c);

    template<class ForwardIterator>
    auto shannon_cost(ForwardIterator first, ForwardIterator last);

    template<class Container>
    auto oracle_snr(Container const & signal, Container const & noise);

    template<class Container>
    auto oracle_snr_db(Container const & signal, Container const & noise);

    template<class Container>
    auto m2m4_snr_estimator(Container const & noisy_signal, typename Container::value_type estimated_signal_kurtosis=1, typename Container::value_type estimate_noise_kurtosis=3);

    template<class Container>
    auto m2m4_snr_estimator_db(Container const & noisy_signal,typename Container::value_type estimated_signal_kurtosis=1, typename Container::value_type estimate_noise_kurtosis=3);

}}}
``

[heading Description]

The file `boost/math/tools/signal_statistics.hpp` is a set of facilities for computing quantities commonly used in signal analysis.

Our examples use `std::vector<double>` to hold the data, but this not required.
In general, you can store your data in an Eigen array, and Armadillo vector, `std::array`, and for many of the routines, a `std::forward_list`.
These routines are usable in float, double, long double, and Boost.Multiprecision precision, as well as their complex extensions whenever the computation is well-defined.
For certain operations (total variation, for example) integer inputs are supported.

[heading Absolute Median]

The absolute median is used in signal processing, where the median of the magnitude of the coefficients in some expansion are used to estimate noise variance.
See [@https://wavelet-tour.github.io/ Mallat] for details.
The absolute median supports both real and complex arithmetic, modifies its input, and requires random access iterators.

    std::vector<double> v{-1, 1};
    double m = boost::math::tools::absolute_median(v.begin(), v.end());
    // m = 1

[heading Absolute Gini Coefficient]

The Gini coefficient, first used to measure wealth inequality, is also one of the best measures of the sparsity of an expansion in a basis.
A sparse expansion has most of its norm concentrated in just a few coefficients, making the connection with wealth inequality obvious.
However, for measuring sparsity, the phase of the numbers is irrelevant, so we provide the `absolute_gini_coefficient`:

    std::vector<std::complex<double>> v{{0,1}, {0,0}, {0,0}, {0,0}};
    double abs_gini = boost::math::tools::absolute_gini_coefficient(v.begin(), v.end());
    // now abs_gini = 1

    std::vector<std::complex<double>> w{{0,1}, {1,0}, {0,-1}, {-1,0}};
    double abs_gini = boost::math::tools::absolute_gini_coefficient(w.begin(), w.end());
    // now abs_gini = 0

    std::vector<double> u{-1, 1, -1};
    double abs_gini = boost::math::tools::absolute_gini_coefficient(u.begin(), u.end());
    // now abs_gini = 0

Wikipedia calls our scaling a "sample Gini coefficient".
We chose this scaling because it always returns unity for a vector which has only one nonzero coefficient,
whereas the value of the population Gini coefficient of a vector with one non-zero element is dependent on the length of the input.

If sorting the input data is too much expense for a sparsity measure (is it going to be perfect anyway?),
consider calculating the Hoyer sparsity instead.

[heading Hoyer Sparsity]

The Hoyer sparsity measures a normalized ratio of the \u2113[super 1] and \u2113[super 2] norms.
As the name suggests, it is used to measure sparsity in an expansion in some basis.

The Hoyer sparsity computes ([radic]/N/ - \u2113[super 1](v)/\u2113[super 2](v))/([radic]N -1).
For details, see [@https://arxiv.org/pdf/0811.4706.pdf Hurley and Rickard].

Usage:

    std::vector<Real> v{1,0,0};
    Real hs = boost::math::tools::hoyer_sparsity(v);
    // hs = 1
    std::vector<Real> v{1,-1,1};
    Real hs = boost::math::tools::hoyer_sparsity(v.begin(), v.end());
    // hs = 0

The container must be forward iterable and the contents are not modified.
Accepts real, complex, and integer inputs. If the input is an integral type, the output is a double precision float.

[heading Shannon Entropy]

    std::vector<double> v{1/2.0, 1/2.0};
    double Hs = boost::math::tools::shannon_entropy(v.begin(), v.end());
    // Hs = ln(2).

The Shannon entropy only supports non-negative real-valued inputs, presumably for interpretational purposes in the range [0,1]-though this is not enforced.
The natural logarithm is used to compute the Shannon entropy; all other "Shannon entropies" are readily obtained by change of log base.

[heading Shannon Cost]

    std::vector<double> v{-1, 1,-1};
    double Ks = boost::math::tools::shannon_cost(v.begin(), v.end());
    // Ks = 0; concentration of the vector is minimized.

The Shannon cost is a modified version of the Shannon entropy used in signal processing and data compression.
The useful properties of the Shannon cost are /K/[sub /s/](0) = 0 and /K/[sub /s/](/v/\u2295 /w/) = /K/[sub /s/](v) + /K/[sub /s/](w).
See [@https://doi.org/10.1007/978-3-642-56702-5 Ripples in Mathematics] for details.

[heading Oracle Signal-to-noise ratio]

The function `oracle_snr` computes the ratio \u2016 /s/ \u2016[sub 2][super 2] / \u2016 /w/ \u2016[sub 2][super 2], where /s/ is signal and /w/ is noise.
The function `oracle_snr_db` computes 10`log`[sub 10](\u2016 /s/ \u2016[super 2] / \u2016 /w/ \u2016[super 2]).
In general, one does not know how to decompose a real signal /x/ into /s/ + /w/ and as such /s/ is regarded as oracle information.
Hence this function is mainly useful for unit testing other SNR measurements.

Usage:

    std::vector<double> signal(500, 3.2);
    std::vector<double> noise(500);
    // fill 'noise' with Gaussian white noise...
    double snr_db = boost::math::tools::oracle_snr_db(signal, noise);
    double snr = boost::math::tools::oracle_snr(signal, noise);

The call should return the same value as [@https://www.mathworks.com/help/signal/ref/snr.html Matlab's `snr`].

The input can be real, complex, or integral.
Integral inputs produce double precision floating point outputs.
The input data is not modified and must satisfy the requirements of a `RandomAccessContainer`.

[heading /M/[sub 2]/M/[sub 4] SNR Estimation]

Estimates the SNR of a noisy signal via the /M/[sub 2]/M/[sub 4] method.
See [@https://doi.org/10.1109/26.871393  Pauluzzi and N.C. Beaulieu] and [@https://doi.org/10.1109/ISIT.1994.394869 Matzner and Englberger] for details.

    std::vector<double> noisy_signal(512);
    // fill noisy_signal with data contaminated by Gaussian white noise:
    double est_snr = boost::math::tools::m2m4_snr_estimator_db(noisy_signal);

The /M/[sub 2]/M/[sub 4] SNR estimator is an "in-service" estimator, meaning that the estimate is made using the noisy, data-bearing signal, and does not require a background estimate.
This estimator has been found to be work best between roughly -3 and 15db, tending to overestimate the noise below -3db, and underestimate the noise above 15db.
See [@https://www.mdpi.com/2078-2489/8/3/75/pdf Xue et al] for details.

The /M/[sub 2]/M/[sub 4] SNR estimator, by default, assumes that the kurtosis of the signal is 1 and the kurtosis of the noise is 3, the latter corresponding to Gaussian noise.
These parameters, however, can be overridden:

    std::vector<double> noisy_signal(512);
    // fill noisy_signal with the data:
    double signal_kurtosis = 1.5;
    // Noise is assumed to follow Laplace distribution, which has kurtosis of 6:
    double noise_kurtosis = 6;
    double est_snr = boost::math::tools::m2m4_snr_estimator_db(noisy_signal, signal_kurtosis, noise_kurtosis);

Now, technically the method is a "blind SNR estimator", meaning that the no /a-priori/ information about the signal is required to use the method.
However, the performance of the method is /vastly/ better if you can come up with a better estimate of the signal and noise kurtosis.
How can we do this? Suppose we know that the SNR is much greater than 1.
Then we can estimate the signal kurtosis simply by using the noisy signal kurtosis.
If the SNR is much less than one, this method breaks down as the noisy signal kurtosis will tend to the noise kurtosis-though in this limit we have an excellent estimator of the noise kurtosis!
In addition, if you have a model of what your signal should look like, you can precompute the signal kurtosis.
For example, sinusoids have a kurtosis of 1.5.
See [@http://www.jcomputers.us/vol8/jcp0808-21.pdf here] for a study which uses estimates of this sort to improve the performance of the /M/[sub 2]/M/[sub 4] estimator.


/Nota bene/: The traditional definition of SNR is /not/ mean invariant.
By this we mean that if a constant is added to every sample of a signal, the SNR is changed.
For example, adding DC bias to a signal changes its SNR.
For most use cases, this is really not what you intend; for example a signal consisting of zeros plus Gaussian noise has an SNR of zero,
whereas a signal with a constant DC bias and random Gaussian noise might have a very large SNR.

The /M/[sub 2]/M/[sub 4] SNR estimator is computed from mean-invariant quantities,
and hence it should really be compared to the mean-invariant SNR.

/Nota bene/: This computation requires the solution of a system of quadratic equations involving the noise kurtosis, the signal kurtosis, and the second and fourth moments of the data.
There is no guarantee that a solution of this system exists for all value of these parameters, in fact nonexistence can easily be demonstrated for certain data.
If there is no solution to the system, then failure is communicated by returning NaNs.

The author has not managed to fully characterize the conditions under which a real solution with /S > 0/ and /N >0/ exists.
However, a very intuitive example demonstrates why nonexistence can occur.
One case is where both the signal and noise kurtosis are assumed to be equal to three.
Then the method has no mechanism for distinguishing the signal from the noise, and the solution is non-unique.


[heading References]

* Higham, Nicholas J. ['Accuracy and stability of numerical algorithms.] Vol. 80. Siam, 2002.
* Mallat, Stephane. ['A wavelet tour of signal processing: the sparse way.] Academic press, 2008.
* Hurley, Niall, and Scott Rickard. ['Comparing measures of sparsity.] IEEE Transactions on Information Theory 55.10 (2009): 4723-4741.
* Jensen, Arne, and Anders la Cour-Harbo. ['Ripples in mathematics: the discrete wavelet transform.] Springer Science & Business Media, 2001.
* D. R. Pauluzzi and N. C. Beaulieu, ['A comparison of SNR estimation techniques for the AWGN channel,] IEEE Trans. Communications, Vol. 48, No. 10, pp. 1681-1691, 2000.


[endsect]
[/section:signal_statistics Signal Statistics]
